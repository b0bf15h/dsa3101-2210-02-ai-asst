{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae7787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(name)s -  %(message)s\", level=logging.WARNING)\n",
    "logging.getLogger(\"haystack\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78804c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "# make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted\n",
    "doc_index = \"val_docs\"\n",
    "label_index = \"val_labels\"\n",
    "\n",
    "# Get the host where Elasticsearch is running, default to localhost\n",
    "host = os.environ.get(\"ELASTICSEARCH_HOST\", \"localhost\")\n",
    "\n",
    "# Connect to Elasticsearch\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=host,\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=doc_index,\n",
    "    label_index=label_index,\n",
    "    embedding_field=\"emb\",\n",
    "    embedding_dim=768,\n",
    "    excluded_meta_data=[\"emb\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f0c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "# Add evaluation data to Elasticsearch Document Store\n",
    "# We first delete the custom tutorial indices to not have duplicate elements\n",
    "# and also split our documents into shorter passages using the PreProcessor\n",
    "preprocessor = PreProcessor(\n",
    "    split_by=\"word\",\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"Annotation/Labels/answers.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c7161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e12e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import FARMReader\n",
    "\n",
    "reader = FARMReader(\"deepset/roberta-base-squad2\", top_k=4, return_no_answer=True)\n",
    "\n",
    "# Define a pipeline consisting of the initialized retriever and reader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "pipeline = ExtractiveQAPipeline(reader=reader, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.schema import EvaluationResult, MultiLabel\n",
    "\n",
    "# We can load evaluation labels from the document store\n",
    "# We are also opting to filter out no_answer samples\n",
    "eval_labels = document_store.get_all_labels_aggregated(drop_negative_labels=True, drop_no_answers=True)\n",
    "\n",
    "# Similar to pipeline.run() we can execute pipeline.eval()\n",
    "eval_result = pipeline.eval(labels=eval_labels, params={\"Retriever\": {\"top_k\": 5}}) # pipeline uses pipeline from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2724acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_result = eval_result[\"Retriever\"]\n",
    "retriever_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2660f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_result = eval_result[\"Reader\"]\n",
    "reader_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9229e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1201210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
